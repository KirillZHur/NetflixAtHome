# NetflixAtHome

Проект онлайн-кинотеатра с микросервисной архитектурой, поиском по каталогу фильмов, системой авторизации, административной панелью, аналитикой пользовательской активности и ETL-пайплайном.

## О проекте

**NetflixAtHome** — учебный проект (Python: продвинутый уровень), целью которого является разработка полноценной системы для просмотра и поиска фильмов с поддержкой поискового движка, аналитики и масштабируемой архитектуры.

**Команда проекта и роли:**

* Журавлев Кирилл — М8О-102СВ-25 — фронтенд для пользователя, настройка фронтенда админки, сервис авторизации;
* Кудрин Ярослав — М8О-102СВ-25 — сервисы для сбора и просмотра пользовательских метрик, разработка архитектуры, сбор общего docker-compose;
* Русаков Александр — М8О-103СВ-25 — сервис для просмотра контента, ETL пайплайн для обновления хранилища, настройка трейсинга;
* Катин Иван — М8О-103СВ-25 — админка для управления фильмами, файловое хранилище, сбор логов.

## Цели и задачи

* Организовать систему просмотра и поиска фильмов с использованием поискового движка
* Реализовать административную панель для управления контентом
* Создать дашборд аналитики просмотров и пользовательской активности
* Построить ETL-пайплайн для переноса данных о фильмах в Elasticsearch
* Организовать сбор пользовательской активности и потоковое получение файлов из S3

## Функциональные требования

### Админка

* Авторизация с проверкой роли
* CRUD для фильмов, жанров и актёров
* Добавление превью фильма
* Загрузка фильма для возможности его просмотра

### Авторизация

* Регистрация и логин пользователей
* JWT-аутентификация
* Роли и права доступа

### Контент-сервис

* Каталог фильмов
* Поиск и фильтрация
* Авторизация
* Просмотр фильма

### Метрики и аналитика

* Сбор пользовательской активности
* Отображение метрик в Grafana

## Нефункциональные требования

* **Доступность:** healthchecks, автоперезапуск контейнеров, rate-limit через Redis
* **Производительность:** низкая латентность за счёт Elasticsearch и Redis, асинхронный сбор метрик
* **Масштабируемость:** горизонтальное масштабирование stateless-сервисов и хранилищ
* **Безопасность:** JWT, изоляция сервисов, секреты через переменные окружения
* **Синхронизация:** асинхронная репликация данных из Postgres в Elasticsearch
* **Наблюдаемость и хранение:** логирование, отправка метрик в ClickHouse через Kafka без влияния на пользовательский поток, резервное копирование данных, дашборды в Grafana

## Архитектура решения

![архитектура](images/architecture.png)

## Админка

![админка](images/admin.png)

## Страница авторизации

![авторизация](images/auth.png)

![регистрация](images/reg.png)

## Главная страница

![главная](images/main.png)

## Страница фильма

![фильм](images/movie.png)

## Страница плеера

![плеер](images/player.png)

## Метрики

![метрики](images/metrics.png)

---

## 1. Auth

```bash
# Постгрес для админки
docker-compose up redis

# База для сервиса авторизации
docker-compose up database

# Cервис авторизации
docker-compose up nx_auth
```

Swagger будет доступен по адресу: [http://localhost:8001/api/openapi](http://localhost:8001/api/openapi)

## 2. Admin

```bash
# База для сервиса админки
docker-compose up database_nx_admin

# Админка для фильмов
docker-compose up nx_admin

# nginx, проксирует админку
docker-compose up nginx
```

Админка будет доступна по адресу: [http://localhost:8000/admin/](http://localhost:8000/admin/)

## 3. Content

```bash
# Elasticsearch для хранения
docker-compose up elasticsearch

# Контент-сервис
docker-compose up nx_backend
```

Swagger: [http://localhost:8002/api/openapi](http://localhost:8002/api/openapi)

## 4. ETL

```bash
# Контейнер с ETL
docker-compose up nx_etl
```

## 5. Пользовательские метрики

### 5.1. Запуск нужных контейнеров

```bash
make up_kafka

make up_clickhouse

docker-compose up -d grafana consumer_user consumer_film nx_metrics
```

### 5.2. Вход в Grafana

Графана достпна по адресу ```localhost:3000```. Логин и пароль: `admin / admin`

### 5.3. Настройка источника данных ClickHouse

1. Добавить источник данных **Altinity plugin for ClickHouse**
2. В поле URL указать:

   ```
   http://clickhouse-node1:8123/
   ```
3. Сохранить источник данных

### 5.4. Импорт dashboard

1. Перейти в создание дашборда и выбрать **Import dashboard**
2. Выбрать файл `./grafana_dashboard/dashboard.json`
3. Нажать **Import**
4. Во всех панелях изменить источник данных на созданный ранее
5. Сохранить дашборд и нажать **Refresh**, если данные не отобразились
   
## 6. Трейсинг

```bash
docker-compose up -d jaeger
```

Jaeger UI будет доступен по адресу: [http://localhost:16686/](http://localhost:16686/)

## 7. Логи

### 7.1. Запуск

```bash
docker-compose up -d logstash kibana
```

### 7.2. Импорт data_value

1. Management -> Stack Management (справа на панели)
2. Перейти в Kibana -> Saved Objects
3. Нажать **Import**
4. Загрузить  [export.ndjson](./logging/export.ndjson)

### 7.3 Просмотр метрик

1. Перейти в Analytics -> Discover (справа на панели) 